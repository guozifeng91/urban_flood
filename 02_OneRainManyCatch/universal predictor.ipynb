{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fe\n",
    "import load_data\n",
    "import nn_models\n",
    "import lossPloter as lp\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image resize options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_rs_0.5\n"
     ]
    }
   ],
   "source": [
    "patch_size = 384\n",
    "patch_name = \"\" if patch_size==256 else \"_p_\" + str(patch_size)\n",
    "\n",
    "# resize the input image to smaller size so that the same patch size covers\n",
    "# larger area, from which the model may learn more global features\n",
    "resize_scale = 0.5\n",
    "resize_name = \"\" if resize_scale==1 else \"_rs_\" + str(resize_scale)\n",
    "print(resize_name)\n",
    "\n",
    "def resize_and_pad(nd_array, scale, patch_size):\n",
    "    '''\n",
    "    resize and pad the input array, so that the resolution fits the need, and the image is large enough for at least one patch\n",
    "    '''\n",
    "    if scale == 1:\n",
    "        return nd_array\n",
    "    h = nd_array.shape[0]\n",
    "    w = nd_array.shape[1]\n",
    "    h2,w2 = round(h*scale), round(w*scale)\n",
    "    \n",
    "    nd_array = cv2.resize(nd_array, (w2,h2))\n",
    "    \n",
    "    pad_h = max(0, 1 + (patch_size - h2) // 2)\n",
    "    pad_w = max(0, 1 + (patch_size - w2) // 2)\n",
    "    \n",
    "    if pad_h > 0 or pad_w > 0:\n",
    "        print (nd_array.shape)\n",
    "        nd_array = np.pad(nd_array, ((pad_h, pad_h), (pad_w, pad_w)), \"edge\")\n",
    "        print (\"\\t pad to\", nd_array.shape)\n",
    "        \n",
    "    return nd_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load catchmant names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['669', '550', '443', '781', '524', '682', '848', '453', '358', '812', '372', '344', '552', '667', '786', '678', '442', '744', '661', '555', '665', '454', '762', '510', '488', '468', '685', '390', '502', '688', '564', '814', '778', '467', '787', '312', '709', '313', '777', '551', '388', '483', '509', '813', '302', '670', '660', '315', '683', '373', '466', '580', '681', '676', '684', '425', '501', '359', '745', '441'] ['859', '556', '333', '366', '763', '671', '689', '464', '553', '447', '663', '462', '849', '367', '528', '691', '868', '721', '334', '724', '465', '549', '565', '557', '484', '677', '435', '767', '843', '764']\n"
     ]
    }
   ],
   "source": [
    "catchment_root = \"C:/Users/guo zifeng/Documents/2019 spring/00_Flood/03_Universal/catchments\"\n",
    "seed = 1\n",
    "propotion = 3\n",
    "load_num = 90 # set to None to load all\n",
    "\n",
    "random.seed(seed)\n",
    "with open(catchment_root + \"/catchments.txt\", \"r\") as text_file:\n",
    "    catchments = [s.strip() for s in text_file.readlines()]\n",
    "    random.shuffle(catchments)\n",
    "\n",
    "if load_num is not None:\n",
    "    catchments = catchments[:load_num]\n",
    "\n",
    "catchments_train = catchments[len(catchments)//propotion:]\n",
    "catchments_test = catchments[:len(catchments)//propotion]\n",
    "\n",
    "print(catchments_train,catchments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specify the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segnet_default-NH0GD1l3\n",
    "fe_x = fe.Features([fe.NormalizedHeight([]), fe.GeographicByDilate(1, keep_channels=[0,1,4])])\n",
    "#fe_x = fe.Features([fe.HeightToDepth(scale = 0.01), fe.GeographicByDilate(1, keep_channels=[0,1,4])])\n",
    "\n",
    "# segnet_default-NH0GK1-1fGK9-81fGK27-729f\n",
    "# fe_x = fe.Features([fe.NormalizedHeight([]), fe.GeographicByKernel(1, 1), fe.GeographicByKernel(9, 81), fe.GeographicByKernel(27, 729)])\n",
    "\n",
    "# segnet_default-NH4\n",
    "# fe_x = fe.Features([fe.NormalizedHeight([64, 256, 512, 1024])])\n",
    "\n",
    "# segnet_default-NH0GD1l1GD9l1GD81l1\n",
    "# fe_x = fe.Features([fe.NormalizedHeight([]), fe.GeographicByDilate(1, keep_channels=[1]), fe.GeographicByDilate(9, keep_channels=[1]),  fe.GeographicByDilate(81, keep_channels=[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load all images into the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 312)\n",
      "\t pad to (462, 386)\n",
      "(462, 312)\n",
      "\t pad to (462, 386)\n"
     ]
    }
   ],
   "source": [
    "fe.DEBUG=False # dont show the debug message\n",
    "\n",
    "nd_img_train = [np.concatenate([fe_x.features(resize_and_pad(np.load(os.path.join(catchment_root, c + \"_dem.npy\")), resize_scale, patch_size)),resize_and_pad(np.load(os.path.join(catchment_root, c + \"_waterdepth.npy\")),resize_scale, patch_size)[...,None]],axis=-1) for c in catchments_train]\n",
    "nd_img_test = [np.concatenate([fe_x.features(resize_and_pad(np.load(os.path.join(catchment_root, c + \"_dem.npy\")),resize_scale, patch_size)),resize_and_pad(np.load(os.path.join(catchment_root, c + \"_waterdepth.npy\")),resize_scale, patch_size)[...,None]],axis=-1) for c in catchments_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate patches from in-memory images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800 patches in total\n",
      "5411 patches in total\n"
     ]
    }
   ],
   "source": [
    "# (Ellipsis, 0) means if all channels is 0\n",
    "patch_train = load_data.PatchFromImage(nd_img_train, patch_size, Ellipsis, 0, ratio=5, batch_size=8,augmentation=True)\n",
    "patch_test = load_data.PatchFromImage(nd_img_test, patch_size, Ellipsis, 0, ratio=5, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel [7, 7] out_channel 32\n",
      "\t Tensor(\"encode0-0:0\", shape=(?, 384, 384, 32), dtype=float32)\n",
      "\t Tensor(\"encode0-1:0\", shape=(?, 384, 384, 32), dtype=float32)\n",
      "\t Tensor(\"encode0-p:0\", shape=(?, 192, 192, 32), dtype=float32)\n",
      "kernel [7, 7] out_channel 64\n",
      "\t Tensor(\"encode1-0:0\", shape=(?, 192, 192, 64), dtype=float32)\n",
      "\t Tensor(\"encode1-1:0\", shape=(?, 192, 192, 64), dtype=float32)\n",
      "\t Tensor(\"encode1-p:0\", shape=(?, 96, 96, 64), dtype=float32)\n",
      "kernel [7, 7] out_channel 128\n",
      "\t Tensor(\"encode2-0:0\", shape=(?, 96, 96, 128), dtype=float32)\n",
      "\t Tensor(\"encode2-1:0\", shape=(?, 96, 96, 128), dtype=float32)\n",
      "\t Tensor(\"encode2-p:0\", shape=(?, 48, 48, 128), dtype=float32)\n",
      "kernel [7, 7] out_channel 128\n",
      "\t Tensor(\"encode3-0:0\", shape=(?, 48, 48, 128), dtype=float32)\n",
      "\t Tensor(\"encode3-1:0\", shape=(?, 48, 48, 128), dtype=float32)\n",
      "\t Tensor(\"encode3-p:0\", shape=(?, 24, 24, 128), dtype=float32)\n",
      "\t Tensor(\"latent-0:0\", shape=(?, 24, 24, 128), dtype=float32)\n",
      "\t Tensor(\"latent-1:0\", shape=(?, 24, 24, 128), dtype=float32)\n",
      "kernel [7, 7] out_channel 128\n",
      "output shape [48, 48]\n",
      "\t Tensor(\"decode0-dc:0\", shape=(?, 48, 48, 128), dtype=float32)\n",
      "\t Tensor(\"decode0-conc:0\", shape=(?, 48, 48, 256), dtype=float32)\n",
      "\t Tensor(\"decode0-0:0\", shape=(?, 48, 48, 128), dtype=float32)\n",
      "\t Tensor(\"decode0-1:0\", shape=(?, 48, 48, 128), dtype=float32)\n",
      "kernel [7, 7] out_channel 128\n",
      "output shape [96, 96]\n",
      "\t Tensor(\"decode1-dc:0\", shape=(?, 96, 96, 128), dtype=float32)\n",
      "\t Tensor(\"decode1-conc:0\", shape=(?, 96, 96, 256), dtype=float32)\n",
      "\t Tensor(\"decode1-0:0\", shape=(?, 96, 96, 128), dtype=float32)\n",
      "\t Tensor(\"decode1-1:0\", shape=(?, 96, 96, 128), dtype=float32)\n",
      "kernel [7, 7] out_channel 128\n",
      "output shape [192, 192]\n",
      "\t Tensor(\"decode2-dc:0\", shape=(?, 192, 192, 64), dtype=float32)\n",
      "\t Tensor(\"decode2-conc:0\", shape=(?, 192, 192, 128), dtype=float32)\n",
      "\t Tensor(\"decode2-0:0\", shape=(?, 192, 192, 64), dtype=float32)\n",
      "\t Tensor(\"decode2-1:0\", shape=(?, 192, 192, 64), dtype=float32)\n",
      "kernel [7, 7] out_channel 128\n",
      "output shape [384, 384]\n",
      "\t Tensor(\"decode3-dc:0\", shape=(?, 384, 384, 32), dtype=float32)\n",
      "\t Tensor(\"decode3-conc:0\", shape=(?, 384, 384, 64), dtype=float32)\n",
      "\t Tensor(\"decode3-0:0\", shape=(?, 384, 384, 32), dtype=float32)\n",
      "\t Tensor(\"decode3-1:0\", shape=(?, 384, 384, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "nnmodel = nn_models.unet_sym_k7_2(fe_x.channels(), 1, img_size=patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss and training operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.00002 #2e-5\n",
    "\n",
    "nnmodel.phs[\"y\"] = tf.placeholder(tf.float32,(None,patch_size,patch_size),name=\"y\")\n",
    "nnmodel.ls[\"loss\"] = tf.reduce_mean(tf.square(nnmodel.phs[\"y\"] - nnmodel.ls[\"prediction\"]),name=\"loss\")\n",
    "train_op = tf.train.AdamOptimizer(LR).minimize(nnmodel.ls[\"loss\"])\n",
    "loss_op = nnmodel.ls[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model unet_sym_kernel7_2-NH0GD1l3_rs_0.5_p_384 will be tested in folder test_folder_unet_sym_kernel7_2-NH0GD1l3_rs_0.5_p_384\n"
     ]
    }
   ],
   "source": [
    "model_path = \"trained_models\"\n",
    "model_name = nnmodel.name + \"-\" + fe_x.name() + resize_name + patch_name\n",
    "\n",
    "test_folder = \"test_folder_\" + model_name\n",
    "\n",
    "print(\"model\", model_name, \"will be tested in folder\", test_folder)\n",
    "\n",
    "# make the test folder\n",
    "if not os.path.exists(test_folder):\n",
    "    os.mkdir(test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "epoch 0 train_loss 0.037060531453776455 test_loss 0.027489068781739675\n",
      "epoch 1 train_loss 0.03117931850932085 test_loss 0.027615815123881556\n",
      "epoch 2 train_loss 0.028338932957717035 test_loss 0.03348210864415615\n",
      "epoch 3 train_loss 0.024128134515180828 test_loss 0.02451544529221886\n",
      "epoch 4 train_loss 0.02253015158022877 test_loss 0.025780414507629423\n",
      "epoch 5 train_loss 0.02064817090112243 test_loss 0.024570174270379667\n",
      "epoch 6 train_loss 0.018471673374808338 test_loss 0.023726280144466694\n",
      "epoch 7 train_loss 0.017854937743518758 test_loss 0.034621294348141624\n",
      "epoch 8 train_loss 0.01579797515823018 test_loss 0.029686150589010002\n",
      "epoch 9 train_loss 0.014102338537852225 test_loss 0.02236686693332495\n",
      "epoch 10 train_loss 0.012945228926122938 test_loss 0.024527753808706216\n",
      "epoch 11 train_loss 0.012108647497888241 test_loss 0.021293939271476808\n",
      "epoch 12 train_loss 0.010803708430797246 test_loss 0.020873469605792914\n",
      "epoch 13 train_loss 0.009755730773174456 test_loss 0.021183421884483192\n",
      "epoch 14 train_loss 0.008795173328847836 test_loss 0.02175887212515953\n",
      "epoch 15 train_loss 0.008346406068756348 test_loss 0.021081978116257383\n",
      "epoch 16 train_loss 0.008398927393536915 test_loss 0.021103004407102555\n",
      "epoch 17 train_loss 0.007114699274786901 test_loss 0.02104643531720755\n",
      "epoch 18 train_loss 0.007258805852277431 test_loss 0.022427961676164173\n",
      "epoch 19 train_loss 0.006107263731063102 test_loss 0.02065345465581853\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b1a09df44ba5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mxy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpatch_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mphs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# record batch loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guo zifeng\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guo zifeng\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guo zifeng\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guo zifeng\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guo zifeng\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guo zifeng\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "last_epoch = 0\n",
    "model_id = \"/-\" + str(last_epoch-1)\n",
    "\n",
    "epoch = 40\n",
    "save_freq = 10\n",
    "\n",
    "phs = nnmodel.phs\n",
    "\n",
    "# loss calculator\n",
    "train_loss = lp.Epoch_Loss()\n",
    "test_loss = lp.Epoch_Loss()\n",
    "\n",
    "%matplotlib qt\n",
    "ploter = lp.Loss_Ploter()\n",
    "\n",
    "# recover the loss record\n",
    "if last_epoch > 0:\n",
    "    print(\"restoring\")\n",
    "    ploter.load_record(model_path, model_name)\n",
    "    saver.restore(sess,os.path.join(model_path,model_name+model_id))\n",
    "\n",
    "print(\"training\")\n",
    "\n",
    "for e in range(epoch):\n",
    "    test_loss.clear()\n",
    "    train_loss.clear()\n",
    "\n",
    "    # 1. training\n",
    "    while not patch_train.end_of_epoch():\n",
    "        xy=patch_train.next_batch()\n",
    "\n",
    "        _, loss_val = sess.run([train_op,loss_op], feed_dict={phs[\"x\"]:xy[:,:,:,:-1], phs[\"y\"]:xy[:,:,:,-1]})\n",
    "\n",
    "        # record batch loss\n",
    "        train_loss.put_batch(loss_val)\n",
    "        ploter.put_batch_loss(loss_val)\n",
    "\n",
    "        # display batch loss curve\n",
    "        if (ploter.count % 6==5):\n",
    "            ploter.plot()\n",
    "\n",
    "    # 2. testing\n",
    "    while not patch_test.end_of_epoch():\n",
    "        xy=patch_test.next_batch()\n",
    "        loss_val = sess.run(loss_op, feed_dict={phs[\"x\"]:xy[:,:,:,:-1], phs[\"y\"]:xy[:,:,:,-1]})\n",
    "        test_loss.put_batch(loss_val)\n",
    "\n",
    "    ploter.put_epoch_loss(train_loss.get_epoch_loss(), test_loss.get_epoch_loss())\n",
    "    print(\"epoch\",e + last_epoch, \"train_loss\",train_loss.get_epoch_loss(),\"test_loss\",test_loss.get_epoch_loss())\n",
    "    ploter.plot()\n",
    "    ploter.savefig(\"training_plot.png\")\n",
    "\n",
    "    if e % save_freq == save_freq-1:\n",
    "        saver.save(sess, os.path.join(model_path, model_name+\"/\"),e + last_epoch)\n",
    "        ploter.save_record(model_path, model_name)\n",
    "\n",
    "ploter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savepng(filename, img_array):\n",
    "    cv2.imwrite(filename,cv2.cvtColor(img_array,cv2.COLOR_RGBA2BGRA))\n",
    "\n",
    "def render(nd_array, cmap, vmin=0, vmax = 1, mask_indice=None):\n",
    "    nd_array = (cmap((nd_array - vmin) / (vmax - vmin))*255).astype(np.uint8)\n",
    "    if mask_indice is not None:\n",
    "        nd_array[mask_indice] *= 0\n",
    "    return nd_array\n",
    "\n",
    "def run_test_in_session(model, sess, dem_array, patch_size, batch_size):\n",
    "    ls = model.ls\n",
    "    phs = model.phs\n",
    "\n",
    "    height, width, _ = dem_array.shape\n",
    "    \n",
    "    # necessary data for prediction\n",
    "    sum_x = np.zeros((height,width), dtype=np.float32)\n",
    "    n_x = np.zeros((height,width), dtype=np.float32)\n",
    "    \n",
    "    # generate testing patches\n",
    "    patches=[]\n",
    "    num_patches = 0\n",
    "\n",
    "    # generate patch locations\n",
    "    patches = [[min(h,height-patch_size-1),min(w,width - patch_size-1)] for h in range(0, height,patch_size//2) for w in range(0, width, patch_size//2)]\n",
    "    # select those that contains catchment areas\n",
    "    patches = [[h, w] for h, w in patches if np.any(dem_array[h:h+patch_size,w:w+patch_size,1]>0)]\n",
    "    num_patches = len(patches)\n",
    "   \n",
    "    patches = np.array(patches,dtype=np.uint32)\n",
    "\n",
    "    for i in range(0, num_patches, batch_size):\n",
    "        start = i\n",
    "        end = min(i+batch_size, num_patches)\n",
    "        \n",
    "        cur_batch = patches[start:end]\n",
    "        x = np.array([dem_array[h:h+patch_size,w:w+patch_size] for h,w in cur_batch])\n",
    "        \n",
    "        result = sess.run(ls[\"prediction\"], feed_dict={phs[\"x\"]:x[:,:,:,:-1]})\n",
    "        \n",
    "        for j in range(len(cur_batch)):\n",
    "            h,w = cur_batch[j]\n",
    "            sum_x[h:h+patch_size,w:w+patch_size] += result[j]\n",
    "            n_x[h:h+patch_size,w:w+patch_size] += 1\n",
    "    \n",
    "    mean_x = np.copy(sum_x)\n",
    "    mean_x[n_x>0] /= n_x[n_x>0]\n",
    "    \n",
    "    return mean_x\n",
    "\n",
    "def render_result(location, name, prediction, dem_array):\n",
    "    mask_indice = np.all(dem_array[:,:] == 0, axis=2) # mask\n",
    "    \n",
    "    img = render(prediction, plt.cm.terrain, 0, 5, mask_indice)\n",
    "    cv2.imwrite(os.path.join(location,name+\"_prediction.png\"),cv2.cvtColor(img,cv2.COLOR_RGBA2BGRA))\n",
    "    \n",
    "    img = render(dem_array[:,:,-1], plt.cm.terrain, 0, 5, mask_indice)\n",
    "    cv2.imwrite(os.path.join(location,name+\"_truth.png\"),cv2.cvtColor(img,cv2.COLOR_RGBA2BGRA))\n",
    "    \n",
    "    img = render(dem_array[:,:,0], plt.cm.terrain, -2, 2, mask_indice)\n",
    "    cv2.imwrite(os.path.join(location,name+\"_dem.png\"),cv2.cvtColor(img,cv2.COLOR_RGBA2BGRA))\n",
    "    \n",
    "    error = prediction - dem_array[:,:,-1]\n",
    "    \n",
    "    img = render(error, plt.cm.seismic, -3, 3, mask_indice)\n",
    "    cv2.imwrite(os.path.join(location,name+\"_error.png\"),cv2.cvtColor(img,cv2.COLOR_RGBA2BGRA))\n",
    "    \n",
    "    error = error[np.logical_not(mask_indice)]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    plt.hist(error, bins=[0.3*(i-40/2) for i in range(41)], color = \"gray\", rwidth=0.85)\n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylim((1, len(error)))\n",
    "    plt.xlabel('Prediction Error',fontsize=16)\n",
    "    plt.ylabel('Frequency',fontsize=16)\n",
    "    \n",
    "    plt.savefig(os.path.join(location,name+\"_hist.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restoring\n",
      "INFO:tensorflow:Restoring parameters from trained_models\\unet_sym_kernel7_2-NH0GD1l3_rs_0.5_p_384/-19\n",
      "testing\n"
     ]
    }
   ],
   "source": [
    "last_epoch = 20\n",
    "model_id = \"/-\" + str(last_epoch-1)\n",
    "\n",
    "print(\"restoring\")\n",
    "saver.restore(sess,os.path.join(model_path,model_name+model_id))\n",
    "# tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "print(\"testing\")\n",
    "\n",
    "%matplotlib inline\n",
    "for i in range(20):\n",
    "    result = run_test_in_session(nnmodel, sess, nd_img_train[i] , patch_size, 64)\n",
    "    render_result(test_folder, \"train_\" + str(catchments_train[i]), result, nd_img_train[i])\n",
    "\n",
    "for i in range(len(catchments_test)):\n",
    "    result = run_test_in_session(nnmodel, sess, nd_img_test[i] , patch_size, 64)\n",
    "    render_result(test_folder,  \"test_\" + str(catchments_test[i]), result, nd_img_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
